# UN Reports RAG ğŸ‡ºğŸ‡³

A minimal RAG (Retrieval-Augmented Generation) system for chatting with recent UN public reports. Built with Python, FAISS, OpenAI embeddings, and Streamlit.

## Features

- **ğŸ“Š Recent Focus**: Discovers UN reports from the past 12 months
- **ğŸ” Smart Search**: FAISS vector search with OpenAI or local BGE embeddings  
- **ğŸ’¬ Chat Interface**: Clean Streamlit chat UI with citations
- **ğŸ“š Proper Citations**: Every answer includes UN symbol, date, organ, and source URL
- **ğŸ¤– Respectful Crawling**: 5-second delays, robots.txt compliance
- **ğŸš€ One-Click Deploy**: Ready for Streamlit Community Cloud

## Quick Start

### Prerequisites
- Python 3.11+ (or 3.7+ with compatible packages)
- OpenAI API key (optional - falls back to local BGE embeddings)

### Installation & Setup

```bash
# Clone and navigate
cd ai-un-report

# Install dependencies
make install

# Build complete corpus (discover â†’ fetch â†’ parse â†’ index)
make build

# Launch chat interface (if you want the full UI)
make app
```

**âš ï¸ Note**: Currently configured to use local BGE embeddings due to OpenAI API quota limits. For chat responses, you'll need a valid OpenAI API key.

### Current Status âœ…

The system is **fully functional** with:
- âœ… 1 UN report downloaded and indexed
- âœ… Local BGE embeddings working (384 dimensions)  
- âœ… FAISS similarity search operational
- âœ… All pipeline components tested and working

### Test the System

```bash
# Test core search functionality
python -c "
import sys; sys.path.append('src')
from index import UNReportIndexer
from utils import load_config
indexer = UNReportIndexer(load_config())
indexer.load_index()
results = indexer.search('economic prospects', top_k=1)
print(f'Found: {results[0][\"title\"]}')
"
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Discovery     â”‚â”€â”€â”€â–¶â”‚    Fetch     â”‚â”€â”€â”€â–¶â”‚   Parse     â”‚â”€â”€â”€â–¶â”‚    Index     â”‚
â”‚ (UN reports)    â”‚    â”‚ (PDF files)  â”‚    â”‚ (chunks)    â”‚    â”‚ (embeddings) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                      â”‚
                                                                      â–¼
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚ Streamlit    â”‚
                                                              â”‚ Chat App     â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

- **`discover.py`** - Finds recent UN reports using hybrid approach (RSS + sitemap + curated seeds)
- **`fetch.py`** - Downloads PDF/HTML files with manifest tracking and resume capability
- **`parse.py`** - Extracts text from documents, creates overlapping chunks with metadata
- **`index.py`** - Generates embeddings (OpenAI or local BGE) and builds FAISS index
- **`app.py`** - Streamlit chat interface with RAG pipeline and citation formatting

## Configuration

Edit `config.yaml` to customize:

```yaml
# Data collection
date_window_days: 365
languages: ["en"]
target_bodies: ["General Assembly", "Security Council", "Economic and Social Council"]

# Document processing  
parsing:
  chunk_tokens: 1200
  overlap_tokens: 150

# Retrieval settings
retrieval:
  top_k: 10
  embedding_provider: "openai"  # or "local_bge"
  
# OpenAI settings
openai:
  embedding_model: "text-embedding-3-small"
  chat_model: "gpt-4o-mini"
```

## Usage

### Command Line Tools

```bash
# Run individual pipeline steps
python src/discover.py  # Find reports
python src/fetch.py     # Download files  
python src/parse.py     # Extract & chunk text
python src/index.py     # Create embeddings index

# Full pipeline
make build

# Run evaluation tests
python src/eval.py

# Clean all generated data
make clean
```

### Streamlit App

```bash
make app  # or streamlit run src/app.py
```

Features:
- **Chat Interface**: Ask questions in natural language
- **Citations**: Every answer shows source UN documents with links
- **Corpus Management**: Rebuild index with latest reports
- **Filters**: Search by UN body, date range
- **Example Queries**: Pre-loaded sample questions

### Example Queries

- "What did the Secretary-General report on climate change?"
- "Recent Security Council resolutions on peacekeeping"
- "Economic and Social Council recommendations for development"
- "What are the main challenges mentioned in recent UN reports?"

## Data Sources & Compliance

- **Primary Source**: [UN Digital Library](https://digitallibrary.un.org) 
- **Robots.txt Compliant**: 5-second delays, respects disallowed paths
- **Discovery Method**: Hybrid approach using RSS feeds, sitemap crawling, and curated seeds
- **File Formats**: PDF (PyMuPDF), HTML (trafilatura)

## Deployment

### Streamlit Community Cloud

1. Fork this repository
2. Connect to [Streamlit Cloud](https://streamlit.io/cloud)
3. Set `OPENAI_API_KEY` in secrets
4. Deploy `src/app.py`

### Hugging Face Spaces

1. Create new Space with Streamlit
2. Upload project files
3. Set `OPENAI_API_KEY` in settings
4. The app will auto-deploy

## Development

### Project Structure

```
ai-un-report/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ discover.py     # UN reports discovery
â”‚   â”œâ”€â”€ fetch.py        # File downloading
â”‚   â”œâ”€â”€ parse.py        # Document parsing
â”‚   â”œâ”€â”€ index.py        # FAISS indexing
â”‚   â”œâ”€â”€ app.py          # Streamlit interface
â”‚   â”œâ”€â”€ eval.py         # Evaluation tests
â”‚   â””â”€â”€ utils.py        # Shared utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Downloaded files
â”‚   â”œâ”€â”€ parsed/         # Processed chunks
â”‚   â””â”€â”€ *.faiss         # Vector index
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_all.sh    # Pipeline script
â”œâ”€â”€ config.yaml         # Configuration
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ Makefile           # Build commands
```

### Adding New Features

1. **New UN Bodies**: Add to `target_bodies` in `config.yaml`
2. **Different Languages**: Update `languages` list and modify parsing
3. **Custom Embeddings**: Implement new provider in `index.py`
4. **Enhanced Parsing**: Extend document structure detection in `parse.py`

### Testing

```bash
make test           # Basic import/config tests
python src/eval.py  # Full RAG evaluation with test queries
```

The evaluation runs 10 test queries and checks:
- Retrieval quality (relevant documents found)
- Generation quality (coherent answers with citations)
- Topic coverage (expected concepts mentioned)

## Technical Details

### Embedding Strategy
- **Primary**: OpenAI `text-embedding-3-small` (1536 dimensions)
- **Fallback**: Local BGE `BAAI/bge-small-en-v1.5` (384 dimensions)
- **Index**: FAISS IndexFlatIP with L2 normalization for cosine similarity

### Chunking Strategy
- **Size**: ~1200 tokens (4800 characters)
- **Overlap**: 150 tokens (600 characters)  
- **Boundaries**: Sentence and paragraph aware splitting
- **Metadata**: UN symbol, organ, date, section titles

### Rate Limiting
- **UN Digital Library**: 5-second delays (per robots.txt)
- **OpenAI API**: Batch processing with error handling
- **File Downloads**: Resumable with manifest tracking

## Limitations

- **Scope**: Last 365 days only (configurable)
- **Languages**: English focus (expandable)
- **Discovery**: Currently uses curated seed data + basic automation
- **File Types**: PDF and HTML only
- **Dependencies**: Requires OpenAI API for best performance

## Contributing

1. Fork the repository
2. Create feature branch
3. Add tests for new functionality  
4. Run `make test` and `make lint`
5. Submit pull request

## License

MIT License - see LICENSE file for details.

## Acknowledgments

- **UN Digital Library** for providing public access to UN documents
- **OpenAI** for embedding and chat APIs
- **FAISS** for efficient similarity search
- **Streamlit** for rapid UI development
